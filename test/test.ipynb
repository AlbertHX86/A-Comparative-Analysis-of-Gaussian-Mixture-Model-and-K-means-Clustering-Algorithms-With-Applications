{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.mixture import BayesianGaussianMixture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data generator\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a 2D dataset with 4 clusters\n",
    "n_samples = 500\n",
    "centers = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n",
    "X = []\n",
    "for center in centers:\n",
    "    x = np.random.randn(n_samples, 2) + center\n",
    "    X.append(x)\n",
    "X = np.concatenate(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoclass(X):\n",
    "    min_components = 2\n",
    "    max_components = 10\n",
    "\n",
    "    # Initialize empty lists to store the BIC values and the models\n",
    "    bic_values = []\n",
    "    models = []\n",
    "\n",
    "    # Loop over the range of cluster numbers and fit a model for each\n",
    "    for n_components in range(min_components, max_components+1):\n",
    "\n",
    "        model = BayesianGaussianMixture(\n",
    "            n_components=n_components, max_iter=1000, n_init=1, weight_concentration_prior=1e-3, random_state=42)\n",
    "        model.fit(X)\n",
    "        models.append(model)\n",
    "        log_likelihood = model.score(X)\n",
    "        n_parameters = n_components * (X.shape[1] + 1)\n",
    "        n_samples = X.shape[0]\n",
    "        bic = -2 * log_likelihood + n_parameters * np.log(n_samples)\n",
    "        bic_values.append(bic)\n",
    "\n",
    "    # Find the optimal number of clusters based on the BIC values\n",
    "    K = np.argmin(bic_values) + min_components\n",
    "    return K\n",
    "n_components=autoclass(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers: [[-1.06742775  0.89393312]\n",
      " [ 1.11892045 -0.82668   ]\n",
      " [ 0.936537    1.14980969]\n",
      " [-1.00526465 -1.15720522]]\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=4, random_state=42)\n",
    "gmm.fit(X)\n",
    "\n",
    "# Get the cluster centers\n",
    "centers = gmm.means_\n",
    "\n",
    "# Print the cluster centers\n",
    "print(\"Cluster centers:\", centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.05114392,  0.00284482],\n",
       "       [ 0.99046984,  0.05014578]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def GMM(X, K, max_iter=100, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Fits a Gaussian Mixture Model to the input data X.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : ndarray\n",
    "        The input data, with shape (N, D), where N is the number of data points and D is the number of features.\n",
    "    K : int\n",
    "        The number of components in the mixture model.\n",
    "    max_iter : int, optional\n",
    "        The maximum number of iterations to run the EM algorithm, defaults to 100.\n",
    "    tol : float, optional\n",
    "        The tolerance level for convergence, defaults to 1e-4.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pi : ndarray\n",
    "        The mixing coefficients of the GMM, with shape (K,).\n",
    "    mu : ndarray\n",
    "        The means of the components of the GMM, with shape (K, D).\n",
    "    sigma : ndarray\n",
    "        The covariance matrices of the components of the GMM, with shape (K, D, D).\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialization\n",
    "    N, D = X.shape\n",
    "    pi = np.ones(K) / K\n",
    "    mu = X[np.random.choice(N, K, replace=False)]\n",
    "    sigma = np.tile(np.eye(D), (K, 1, 1))\n",
    "\n",
    "    # EM algorithm\n",
    "    for i in range(max_iter):\n",
    "        # E-step\n",
    "        gamma = np.zeros((N, K))\n",
    "        for j in range(K):\n",
    "            gamma[:, j] = pi[j] * \\\n",
    "                multivariate_normal.pdf(X, mean=mu[j], cov=sigma[j])\n",
    "\n",
    "        gamma /= np.sum(gamma, axis=1, keepdims=True)\n",
    "\n",
    "        # M-step\n",
    "        Nk = np.sum(gamma, axis=0)\n",
    "        pi = Nk / N\n",
    "        mu = np.dot(gamma.T, X) / Nk[:, None]\n",
    "        for j in range(K):\n",
    "            X_centered = X - mu[j]\n",
    "            sigma[j] = np.dot(\n",
    "                (X_centered * gamma[:, j][:, None]).T, X_centered) / Nk[j]\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.abs(np.sum(gamma, axis=0) - N / K).max() < tol:\n",
    "            break\n",
    "\n",
    "    return pi, mu, sigma\n",
    "\n",
    "x=GMM(X,n_components)\n",
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels: [1 1 1 ... 0 0 3]\n",
      "Cluster centers: [[-1.17974893 -1.25743119]\n",
      " [ 1.14924952  1.23694434]\n",
      " [-1.1852623   1.11395896]\n",
      " [ 1.18046857 -1.06130664]]\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Print the cluster labels\n",
    "print(\"Cluster labels:\", labels)\n",
    "\n",
    "# Get the cluster centers\n",
    "centers = kmeans.cluster_centers_\n",
    "\n",
    "# Print the cluster centers\n",
    "print(\"Cluster centers:\", centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means accuracy: 0.5866666666666667\n",
      "GMM accuracy: 0.58\n",
      "KNN accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate a toy dataset\n",
    "X, y = make_blobs(n_samples=500, centers=5, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "split = int(len(X) * 0.7)\n",
    "X_train, y_train = X[:split], y[:split]\n",
    "X_test, y_test = X[split:], y[split:]\n",
    "\n",
    "# K-Means clustering\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(X_train)\n",
    "kmeans_train_preds = kmeans.predict(X_train)\n",
    "kmeans_test_preds = kmeans.predict(X_test)\n",
    "\n",
    "# GMM clustering\n",
    "gmm = GaussianMixture(n_components=5, random_state=42)\n",
    "gmm.fit(X_train)\n",
    "gmm_train_preds = gmm.predict(X_train)\n",
    "gmm_test_preds = gmm.predict(X_test)\n",
    "\n",
    "# K-Nearest Neighbors classification\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_train_preds = knn.predict(X_train)\n",
    "knn_test_preds = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of each model\n",
    "kmeans_acc = accuracy_score(y_test, kmeans_test_preds)\n",
    "gmm_acc = accuracy_score(y_test, gmm_test_preds)\n",
    "knn_acc = accuracy_score(y_test, knn_test_preds)\n",
    "\n",
    "print(\"K-Means accuracy:\", kmeans_acc)\n",
    "print(\"GMM accuracy:\", gmm_acc)\n",
    "print(\"KNN accuracy:\", knn_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
